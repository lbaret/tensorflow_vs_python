{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-25 23:49:58.667695: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from utils.data_management import load_data\n",
    "import config as cfg\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On profite de la puissance de Python : Les dictionnaires\n",
    "datasets_map = {\n",
    "    'cifar': None,\n",
    "    'mnist': None,\n",
    "    'fashion': None\n",
    "}\n",
    "\n",
    "for name in datasets_map.keys():\n",
    "    datasets_map[name] = load_data(name, cfg.DATA_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_map['mnist']['train']['images'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-25 22:41:14.156821: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-25 22:41:14.192713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-25 22:41:14.193040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.095GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 357.69GiB/s\n",
      "2021-07-25 22:41:14.193058: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-25 22:41:14.195770: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-25 22:41:14.195797: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-25 22:41:14.197079: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-25 22:41:14.197262: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-25 22:41:14.197616: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-25 22:41:14.198186: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-25 22:41:14.198236: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-07-25 22:41:14.198244: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-07-25 22:41:14.198570: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-25 22:41:14.199052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-25 22:41:14.199081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
     ]
    }
   ],
   "source": [
    "cifar_ti = datasets_map['cifar']['train']['images']\n",
    "cifar_tl = datasets_map['cifar']['train']['labels']\n",
    "cifar_shape = cifar_ti.shape\n",
    "\n",
    "cifar_train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    cifar_ti.reshape((cifar_shape[0], cifar_shape[2], cifar_shape[3], cifar_shape[1])),\n",
    "    cifar_tl\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((32, 32, 3), ()), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-encodeur\n",
    "\n",
    "Nous commençons par un auto-encodeur en TensorFlow à l'aide d'une classe personnalisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notre bloc encodeur\n",
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, latent_size=8, *args, **kwargs):\n",
    "        super(Encoder, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        # Couches\n",
    "        self.conv1 = layers.Conv2D(filters=4, kernel_size=3, strides=1, padding=\"SAME\", \n",
    "                                   use_bias=True, data_format='channels_last')\n",
    "        self.conv2 = layers.Conv2D(filters=1, kernel_size=3, strides=1, padding=\"SAME\", \n",
    "                                   use_bias=True, data_format='channels_last')\n",
    "        \n",
    "        # Activations\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "        # Couche latente\n",
    "        self.dense = layers.Dense(units=128, use_bias=True)\n",
    "        self.latent = layers.Dense(units=latent_size, use_bias=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.relu(x)\n",
    "        return self.latent(x)\n",
    "\n",
    "# Notre bloc décodeur\n",
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Decoder, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        # Couches\n",
    "        self.de_conv1 = layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding=\"SAME\", \n",
    "                                               use_bias=True, data_format='channels_last')\n",
    "        self.de_conv2 = layers.Conv2DTranspose(filters=4, kernel_size=3, strides=1, padding=\"SAME\", \n",
    "                                               use_bias=True, data_format='channels_last')\n",
    "        \n",
    "        # Activations\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "        # Couche latente\n",
    "        self.dense = layers.Dense(units=784, use_bias=True)\n",
    "        self.de_latent = layers.Dense(units=128, use_bias=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.de_latent(inputs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.de_conv2(x)\n",
    "        x = self.relu(x)\n",
    "        return self.de_conv1(x)\n",
    "\n",
    "\n",
    "# Classe finale : combinaison encodeur - decodeur\n",
    "class ConvolutionalAE(tf.keras.Model):\n",
    "    def __init__(self, latent_size=8, *args, **kwargs):\n",
    "        super(ConvolutionalAE, self).__init__(*args, **kwargs)\n",
    "        self.encoder = Encoder(latent_size=latent_size)\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.encoder(inputs)\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "\n",
    "model = ConvolutionalAE(latent_size=16)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_step(model, loss_object, optimizer, inputs, labels=None):\n",
    "    \"\"\"\n",
    "    Fonction qui va rouler une étape, soit le passage d'une batch d'exemples.\n",
    "    De plus, le graph va se construire durant l'exécution à l'aide de tf.GradientTape().\n",
    "    Les labels peuvent être de type 'None', auquel cas, la sortie sera comparée avec l'entrée.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(inputs, training=True)\n",
    "        if labels is None:\n",
    "            loss = loss_object(inputs, outputs)\n",
    "        else:\n",
    "            loss = loss_object(labels, outputs)\n",
    "    # Le gradient se calcule en dehors du contexte du graph\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # La backpropagation\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    # Le suivi de la loss\n",
    "    train_loss(loss)\n",
    "\n",
    "def train(model, loss_object, optimizer, train_data, epochs=100, use_labels=False):\n",
    "    \"\"\"\n",
    "    Fonction d'entrainement, à chacune des époques, on fait passer l'ensemble du jeu de données.\n",
    "    \"\"\"\n",
    "    for ep in range(epochs):\n",
    "        for (batch, (inputs, labels)) in enumerate(train_data):\n",
    "            if use_labels:\n",
    "                run_step(model, loss_object, optimizer, inputs, labels)\n",
    "            else:\n",
    "                run_step(model, loss_object, optimizer, inputs)\n",
    "            print(f'\\rBatch : {batch + 1}', end='')\n",
    "        print(f'\\rEpoch : {ep+1} / {epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Finir de loader le dataset\n",
    "train_size = len(cifar_train_dataset)\n",
    "train_dataset = cifar_train_dataset.shuffle(2*train_size).batch(64)\n",
    "train(model, loss, optimizer, train_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant ce qu'il serait bien, ce serait de :\n",
    "- Essayer d'ajouter les opérations sur GPU\n",
    "\n",
    "### Graph des opération\n",
    "Je confirme qu'avec **tf.GradientTape()** nous avons bien la construction du graph avec les opérations effectuées durant l'exécution. Le contexte permet d'enregistrer les opération réalisées.\n",
    "\n",
    "Continuer à se renseigner sur le décorateur **@tf.function** : https://www.tensorflow.org/api_docs/python/tf/function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
