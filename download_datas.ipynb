{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Téléchargement et manipulation des données\n",
    "\n",
    "Trois datasets :\n",
    "- CIFAR-10\n",
    "- MNIST\n",
    "- Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from utils.data_management import create_tensor_from_dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_train = datasets.CIFAR10(root='data/cifar_10_train', download=True, train=True, transform=transforms.ToTensor())\n",
    "cifar_test = datasets.CIFAR10(root='data/cifar_10_test', download=True, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loic/.pyenv/versions/3.9.6/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = datasets.MNIST(root='data/mnist_train', download=True, train=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(root='data/mnist_test', download=True, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_train = datasets.FashionMNIST(root='data/mnist_fashion_train', download=True, train=True, transform=transforms.ToTensor())\n",
    "fashion_test = datasets.FashionMNIST(root='data/mnist_fashion_test', download=True, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suite\n",
    "Il faudrait maintenant faire en sorte que nos données soient enregistrés comme des Numpy arrays. Pourquoi ? Afin de les récupérer dans un format générique, à la fois pour PyTorch et pour TensorFlow.\n",
    "\n",
    "Pour se faire, nous pouvons directement récupérer chacune des valeurs, créer une liste et à la fin les stacker dans un tenseur et les convertir en array et sauvegarder ce fichier sous format npy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10\n",
      "\n",
      "\n",
      "Fin\n",
      "MNIST\n",
      "\n",
      "\n",
      "Fin\n",
      "Fashion MNIST\n",
      "\n",
      "\n",
      "Fin\n"
     ]
    }
   ],
   "source": [
    "print('CIFAR-10')\n",
    "cifar_img_train, cifar_lbl_train = create_tensor_from_dataset(cifar_train, train=True)\n",
    "cifar_img_test, cifar_lbl_test = create_tensor_from_dataset(cifar_test, train=False)\n",
    "print('Fin')\n",
    "\n",
    "print('MNIST')\n",
    "mnist_img_train, mnist_lbl_train = create_tensor_from_dataset(mnist_train, train=True)\n",
    "mnist_img_test, mnist_lbl_test = create_tensor_from_dataset(mnist_test, train=False)\n",
    "print('Fin')\n",
    "\n",
    "print('Fashion MNIST')\n",
    "fashion_img_train, fashion_lbl_train = create_tensor_from_dataset(fashion_train, train=True)\n",
    "fashion_img_test, fashion_lbl_test = create_tensor_from_dataset(fashion_test, train=False)\n",
    "print('Fin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vérification des outpus et conversion en np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 3, 32, 32]),\n",
       " torch.Size([50000]),\n",
       " torch.Size([10000, 3, 32, 32]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_img_train.shape, cifar_lbl_train.shape, cifar_img_test.shape, cifar_lbl_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 1, 28, 28]),\n",
       " torch.Size([60000]),\n",
       " torch.Size([10000, 1, 28, 28]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_img_train.shape, mnist_lbl_train.shape, mnist_img_test.shape, mnist_lbl_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 1, 28, 28]),\n",
       " torch.Size([60000]),\n",
       " torch.Size([10000, 1, 28, 28]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_img_train.shape, fashion_lbl_train.shape, fashion_img_test.shape, fashion_lbl_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout est ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10\n",
    "np.save('data/cifar_images_train.npy', cifar_img_train.numpy())\n",
    "np.save('data/cifar_labels_train.npy', cifar_lbl_train.numpy())\n",
    "np.save('data/cifar_images_test.npy', cifar_img_test.numpy())\n",
    "np.save('data/cifar_labels_test.npy', cifar_lbl_test.numpy())\n",
    "\n",
    "# MNIST\n",
    "np.save('data/mnist_images_train.npy', mnist_img_train.numpy())\n",
    "np.save('data/mnist_labels_train.npy', mnist_lbl_train.numpy())\n",
    "np.save('data/mnist_images_test.npy', mnist_img_test.numpy())\n",
    "np.save('data/mnist_labels_test.npy', mnist_lbl_test.numpy())\n",
    "\n",
    "# Fashion MNIST\n",
    "np.save('data/fashion_images_train.npy', fashion_img_train.numpy())\n",
    "np.save('data/fashion_labels_train.npy', fashion_lbl_train.numpy())\n",
    "np.save('data/fashion_images_test.npy', fashion_img_test.numpy())\n",
    "np.save('data/fashion_labels_test.npy', fashion_lbl_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
