{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Téléchargement et manipulation des données\n",
    "\n",
    "Trois datasets :\n",
    "- CIFAR-10\n",
    "- MNIST\n",
    "- Fashion-MNIST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CIFAR-10"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "cifar_train = datasets.CIFAR10(root='data/cifar_10_train', download=True, train=True, transform=transforms.ToTensor())\n",
    "cifar_test = datasets.CIFAR10(root='data/cifar_10_test', download=True, train=False, transform=transforms.ToTensor())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MNIST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "mnist_train = datasets.MNIST(root='data/mnist_train', download=True, train=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(root='data/mnist_test', download=True, train=False, transform=transforms.ToTensor())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/loic/.pyenv/versions/3.9.6/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fashion-MNIST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "fashion_train = datasets.FashionMNIST(root='data/mnist_fashion_train', download=True, train=True, transform=transforms.ToTensor())\n",
    "fashion_test = datasets.FashionMNIST(root='data/mnist_fashion_test', download=True, train=False, transform=transforms.ToTensor())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Suite\n",
    "Il faudrait maintenant faire en sorte que nos données soient enregistrés comme des Numpy arrays. Pourquoi ? Afin de les récupérer dans un format générique, à la fois pour PyTorch et pour TensorFlow.\n",
    "\n",
    "Pour se faire, nous pouvons directement récupérer chacune des valeurs, créer une liste et à la fin les stacker dans un tenseur et les convertir en array et sauvegarder ce fichier sous format npy."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# On factorise le code.\n",
    "def create_final_tensor(dataset, train=True):\n",
    "    list_imgs = []\n",
    "    list_lbls = []\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        img, lbl = dataset[i]\n",
    "        list_imgs.append(img)\n",
    "        list_lbls.append(lbl)\n",
    "        print(f\"\\rStacking {'train' if train else 'test'} : {(i+1) / len(dataset) * 100:.2f}%\", end='')\n",
    "    \n",
    "    tensor_imgs = torch.vstack(list_imgs)\n",
    "    tensor_lbls = torch.tensor(list_lbls)\n",
    "    print('')\n",
    "\n",
    "    return tensor_imgs, tensor_lbls"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "print('CIFAR-10')\n",
    "cifar_img_train, cifar_lbl_train = create_final_tensor(cifar_train, train=True)\n",
    "cifar_img_test, cifar_lbl_test = create_final_tensor(cifar_test, train=False)\n",
    "print('Fin')\n",
    "\n",
    "print('MNIST')\n",
    "mnist_img_train, mnist_lbl_train = create_final_tensor(mnist_train, train=True)\n",
    "mnist_img_test, mnist_lbl_test = create_final_tensor(mnist_test, train=False)\n",
    "print('Fin')\n",
    "\n",
    "print('Fashion MNIST')\n",
    "fashion_img_train, fashion_lbl_train = create_final_tensor(fashion_train, train=True)\n",
    "fashion_img_test, fashion_lbl_test = create_final_tensor(fashion_test, train=False)\n",
    "print('Fin')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CIFAR-10\n",
      "Stacking train : 100.00%\n",
      "Stacking test : 100.00%\n",
      "Fin\n",
      "MNIST\n",
      "Stacking train : 100.00%\n",
      "Stacking test : 100.00%\n",
      "Fin\n",
      "Fashion MNIST\n",
      "Stacking train : 100.00%\n",
      "Stacking test : 100.00%\n",
      "Fin\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Vérification des outpus et conversion en np.array"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "cifar_img_train.shape, cifar_lbl_train.shape, cifar_img_test.shape, cifar_lbl_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([150000, 32, 32]),\n",
       " torch.Size([50000]),\n",
       " torch.Size([30000, 32, 32]),\n",
       " torch.Size([10000]))"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "mnist_img_train.shape, mnist_lbl_train.shape, mnist_img_test.shape, mnist_lbl_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]),\n",
       " torch.Size([60000]),\n",
       " torch.Size([10000, 28, 28]),\n",
       " torch.Size([10000]))"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "fashion_img_train.shape, fashion_lbl_train.shape, fashion_img_test.shape, fashion_lbl_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]),\n",
       " torch.Size([60000]),\n",
       " torch.Size([10000, 28, 28]),\n",
       " torch.Size([10000]))"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tout est ok."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# CIFAR-10\n",
    "np.save('data/cifar_images_train.npy', cifar_img_train.numpy())\n",
    "np.save('data/cifar_labels_train.npy', cifar_lbl_train.numpy())\n",
    "np.save('data/cifar_images_test.npy', cifar_img_test.numpy())\n",
    "np.save('data/cifar_labels_test.npy', cifar_lbl_test.numpy())\n",
    "\n",
    "# MNIST\n",
    "np.save('data/mnist_images_train.npy', mnist_img_train.numpy())\n",
    "np.save('data/mnist_labels_train.npy', mnist_lbl_train.numpy())\n",
    "np.save('data/mnist_images_test.npy', mnist_img_test.numpy())\n",
    "np.save('data/mnist_labels_test.npy', mnist_lbl_test.numpy())\n",
    "\n",
    "# Fashion MNIST\n",
    "np.save('data/fashion_images_train.npy', fashion_img_train.numpy())\n",
    "np.save('data/fashion_labels_train.npy', fashion_lbl_train.numpy())\n",
    "np.save('data/fashion_images_test.npy', fashion_img_test.numpy())\n",
    "np.save('data/fashion_labels_test.npy', fashion_lbl_test.numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}