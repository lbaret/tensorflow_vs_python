{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-24 17:45:17.098440: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from utils.data_management import load_data\n",
    "import config as cfg\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On profite de la puissance de Python : Les dictionnaires\n",
    "datasets_map = {\n",
    "    'cifar': None,\n",
    "    'mnist': None,\n",
    "    'fashion': None\n",
    "}\n",
    "\n",
    "for name in datasets_map.keys():\n",
    "    datasets_map[name] = load_data(name, cfg.DATA_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_map['mnist']['train']['images'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3, 32, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_map['cifar']['train']['images'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-24 17:45:44.935232: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-24 17:45:44.979998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-24 17:45:44.980381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.095GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 357.69GiB/s\n",
      "2021-07-24 17:45:44.980402: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-24 17:45:44.995864: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-24 17:45:44.995899: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-24 17:45:45.003060: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-24 17:45:45.005024: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-24 17:45:45.006827: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-24 17:45:45.010627: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-24 17:45:45.010703: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-07-24 17:45:45.010712: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-07-24 17:45:45.011385: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-24 17:45:45.012007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-24 17:45:45.012018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "2021-07-24 17:45:45.012698: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "cifar_train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    datasets_map['cifar']['train']['images'],\n",
    "    datasets_map['cifar']['train']['labels']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((3, 32, 32), ()), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-encodeur\n",
    "\n",
    "Nous commençons par un auto-encodeur en TensorFlow à l'aide d'une classe personnalisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notre bloc encodeur\n",
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, latent_size=8, *args, **kwargs):\n",
    "        super(Encoder, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        # Couches\n",
    "        self.conv1 = layers.Conv2D(filters=4, kernel_size=3, strides=1, padding=\"SAME\", use_bias=True)\n",
    "        self.conv2 = layers.Conv2D(filters=1, kernel_size=3, strides=1, padding=\"SAME\", use_bias=True)\n",
    "        \n",
    "        # Activations\n",
    "        self.relu = layers.ReLu()\n",
    "        \n",
    "        # Couche latente\n",
    "        self.dense = layers.Dense(units=128, use_bias=True)\n",
    "        self.latent = layers.Dense(units=latent_size, use_bias=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.relu(x)\n",
    "        return self.latent(x)\n",
    "\n",
    "# Notre bloc décodeur\n",
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Decoder, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        # Couches\n",
    "        self.de_conv1 = layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding=\"SAME\", use_bias=True)\n",
    "        self.de_conv2 = layers.Conv2DTranspose(filters=4, kernel_size=3, strides=1, padding=\"SAME\", use_bias=True)\n",
    "        \n",
    "        # Activations\n",
    "        self.relu = layers.ReLu()\n",
    "        \n",
    "        # Couche latente\n",
    "        self.dense = layers.Dense(units=784, use_bias=True)\n",
    "        self.de_latent = layers.Dense(units=128, use_bias=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.de_latent(inputs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.de_conv2(x)\n",
    "        x = self.relu(x)\n",
    "        return self.de_conv1(x)\n",
    "\n",
    "\n",
    "# Classe finale : combinaison encodeur - decodeur\n",
    "class ConvolutionalAE(tf.keras.Model):\n",
    "    def __init__(self, latent_size=8, *args, **kwargs):\n",
    "        super(ConvolutionalAE, self).__init__(*args, **kwargs)\n",
    "        self.encoder = Encoder(latent_size=latent_size)\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.encoder(inputs)\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "\n",
    "model = ConvolutionalAE(latent_size=16)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_step(inputs, labels=None):\n",
    "    \"\"\"\n",
    "    Fonction qui va rouler une étape, soit le passage d'une batch d'exemples.\n",
    "    De plus, le graph va se construire durant l'exécution à l'aide de tf.GradientTape().\n",
    "    Les labels peuvent être de type 'None', auquel cas, la sortie sera comparée avec l'entrée.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(inputs, training=True)\n",
    "        if labels is None:\n",
    "            loss = loss_object(inputs, outputs)\n",
    "        else:\n",
    "            loss = loss_object(labels, outputs)\n",
    "    # Le gradient se calcule en dehors du contexte du graph\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # La backpropagation\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    # Le suivi de la loss\n",
    "    train_loss(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant ce qu'il serait bien, ce serait de :\n",
    "- Développer la fonction d'entrainement (les calculs réalisés lors d'une époque)\n",
    "- Il semblerait qu'avec **tf.GradientTape()** nous avons la construction du graph avec les opérations effectuées durant le run\n",
    "- Construire nos jeux de données séparément avec **tf.data.Dataset**\n",
    "- Somme toute : continuer de suivre le tutoriel : https://www.tensorflow.org/tutorials/quickstart/advanced\n",
    "\n",
    "### Graph des opération\n",
    "Je confirme qu'avec **tf.GradientTape()** nous avons bien la construction du graph avec les opérations effectuées durant l'exécution. Le contexte permet d'enregistrer les opération réalisées.\n",
    "\n",
    "Continuer à se renseigner sur le décorateur **@tf.function** : https://www.tensorflow.org/api_docs/python/tf/function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
